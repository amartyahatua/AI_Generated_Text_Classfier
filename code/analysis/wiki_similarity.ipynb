{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\OneDrive - MNSCU\\Research\\2023_AI_Text_Classification\\AI_Generated_Text_Classfier\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "import numpy as np\n",
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3974, 50786)\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.read_csv('./data/features_GT.csv')\n",
    "df1.sort_values(by='indexes', inplace=True)\n",
    "print(df1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4557, 50786)\n"
     ]
    }
   ],
   "source": [
    "df2 = pd.read_csv('./data/features_ChatGPT.csv')\n",
    "df2.sort_values(by='indexes', inplace=True)\n",
    "print(df2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3643, 50786)\n"
     ]
    }
   ],
   "source": [
    "df1_filtered = df1.loc[df1['indexes'].isin(df2['indexes'])]\n",
    "print(df1_filtered.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3643, 50786)\n"
     ]
    }
   ],
   "source": [
    "df2_filtered = df2.loc[df2['indexes'].isin(df1['indexes'])]\n",
    "print(df2_filtered.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scaler mean :  [1.87782460e+02 1.18323511e+03 6.23811837e+00 3.40145484e+01\n",
      " 3.42327752e+01 2.56848751e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 8.57260500e+00\n",
      " 9.99383253e+00 2.87756974e+01 1.14008870e+01 9.14104216e+00\n",
      " 8.02926679e+00 1.05990390e+01 1.23704912e+01 6.05840005e+00\n",
      " 2.12215207e+01 4.19854151e-02 7.58861542e-02 7.01157543e-02\n",
      " 4.16464565e-02 4.27094388e-02 4.37071065e-02 4.22704968e-02\n",
      " 1.05933527e-01 4.18976376e-02 6.57322406e-02 4.18208612e-02\n",
      " 4.16028739e-02 4.94075877e-02 4.29343990e-02 4.22354436e-02\n",
      " 4.25470375e-02 4.17126971e-02 4.16858150e-02 4.21435145e-02\n",
      " 4.20255434e-02]\n",
      "scaler scale:  [1.70351716e+02 1.10299942e+03 6.64007049e-01 4.62950094e+01\n",
      " 4.07394546e+01 5.33144285e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 2.73225744e+01\n",
      " 8.60905340e+00 2.61316823e+01 9.40943331e+00 5.95514268e+00\n",
      " 5.07847339e+00 1.02929671e+01 1.30756644e+01 4.38914480e+00\n",
      " 2.74447226e+01 2.34595596e-02 7.15685556e-02 5.91458243e-02\n",
      " 2.39630991e-02 2.43114433e-02 2.74165453e-02 2.41133190e-02\n",
      " 9.50811080e-02 2.34653304e-02 5.06368013e-02 2.33632815e-02\n",
      " 2.30359965e-02 3.28518548e-02 2.46390126e-02 2.46885505e-02\n",
      " 2.39887448e-02 2.32566488e-02 2.41008399e-02 2.37150429e-02\n",
      " 2.42683736e-02]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3643/3643 [00:00<00:00, 15209.88it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "x1 = df1_filtered.iloc[:, 3:44]\n",
    "x2 = df2_filtered.iloc[:, 3:44]\n",
    "x_merged = pd.concat([x1, x2], ignore_index = True, sort = False)\n",
    "scaler = StandardScaler().fit(x_merged)\n",
    "print('scaler mean : ', scaler.mean_)\n",
    "print('scaler scale: ', scaler.scale_)\n",
    "x1 = scaler.transform(x1)\n",
    "x2 = scaler.transform(x2)\n",
    "\n",
    "similarities = []\n",
    "for i in tqdm(range(df1_filtered.shape[0])):\n",
    "    try:\n",
    "        gt_features = x1[i]\n",
    "        #print(gt_features.shape)\n",
    "        chatgpt_features = x2[i]\n",
    "        #print(chatgpt_features.shape)\n",
    "        similarity_score = cosine_similarity([gt_features], [chatgpt_features])\n",
    "        #print('row ', i, ': score=', similarity_score)\n",
    "        similarities.append(similarity_score)\n",
    "    except Exception as e:\n",
    "        similarity_score = 0\n",
    "        similarities.append(similarity_score)\n",
    "        print('Cosine error at row ', i, str(e))\n",
    "        break\n",
    "similarities = np.reshape(similarities, (-1,1))\n",
    "similarities = pd.DataFrame(similarities, columns=['Cosine similarity'])\n",
    "similarities.to_csv('./data/wiki_features_similarity_no_tfidf.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scaler mean :  [1.87782460e+02 1.18323511e+03 6.23811837e+00 ... 6.03005484e-04\n",
      " 7.79116701e-04 1.23469147e-03]\n",
      "scaler scale:  [1.70351716e+02 1.10299942e+03 6.64007049e-01 ... 1.00323426e-02\n",
      " 1.01743734e-02 1.94236586e-02]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3643/3643 [00:05<00:00, 675.90it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "x1 = df1_filtered.iloc[:, 3:]\n",
    "x2 = df2_filtered.iloc[:, 3:]\n",
    "x_merged = pd.concat([x1, x2], ignore_index = True, sort = False)\n",
    "scaler = StandardScaler().fit(x_merged)\n",
    "print('scaler mean : ', scaler.mean_)\n",
    "print('scaler scale: ', scaler.scale_)\n",
    "x1 = scaler.transform(x1)\n",
    "x2 = scaler.transform(x2)\n",
    "\n",
    "similarities_full = []\n",
    "for i in tqdm(range(df1_filtered.shape[0])):\n",
    "    try:\n",
    "        gt_features = x1[i]\n",
    "        #print(gt_features.shape)\n",
    "        chatgpt_features = x2[i]\n",
    "        #print(chatgpt_features.shape)\n",
    "        similarity_score = cosine_similarity([gt_features], [chatgpt_features])\n",
    "        #print('row ', i, ': score=', similarity_score)\n",
    "        similarities_full.append(similarity_score)\n",
    "    except Exception as e:\n",
    "        similarity_score = 0\n",
    "        similarities_full.append(similarity_score)\n",
    "        print('Cosine error at row ', i, str(e))\n",
    "        break\n",
    "similarities_full = np.reshape(similarities_full, (-1,1))\n",
    "similarities_full = pd.DataFrame(similarities_full, columns=['Cosine similarity'])\n",
    "similarities_full.to_csv('./data/wiki_features_similarity_with_tfidf.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scaler mean :  [1.87782460e+02 1.18323511e+03 6.23811837e+00 ... 6.03005484e-04\n",
      " 7.79116701e-04 1.23469147e-03]\n",
      "scaler scale:  [1.70351716e+02 1.10299942e+03 6.64007049e-01 ... 1.00323426e-02\n",
      " 1.01743734e-02 1.94236586e-02]\n",
      "pca.explained_variance_ratio_ [0.00673364 0.00531963 0.00425419 ... 0.00027464 0.00027417 0.0002732 ]\n",
      "pca.singular_values_ [1186.3290704  1054.43736588  942.95007053 ...  239.58744016  239.38212764\n",
      "  238.95725349]\n",
      "pca.explained_variance_ratio_ [0.00357574 0.00307535 0.00260167 ... 0.000295   0.00029395 0.00029273]\n",
      "pca.singular_values_ [597.85098647 554.44356862 509.95984971 ... 171.7191562  171.41418255\n",
      " 171.05767835]\n",
      "(3643, 1024) (3643, 1024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3643/3643 [00:00<00:00, 13134.45it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "#########################################################################\n",
    "x1 = df1_filtered.iloc[:, 3:]\n",
    "x2 = df2_filtered.iloc[:, 3:]\n",
    "x_merged = pd.concat([x1, x2], ignore_index = True, sort = False)\n",
    "scaler = StandardScaler().fit(x_merged)\n",
    "print('scaler mean : ', scaler.mean_)\n",
    "print('scaler scale: ', scaler.scale_)\n",
    "x1 = scaler.transform(x1)\n",
    "x2 = scaler.transform(x2)\n",
    "#########################################################################\n",
    "pca1 = PCA(n_components=1024)\n",
    "x1 = pca1.fit_transform(x1)\n",
    "print('pca.explained_variance_ratio_', pca1.explained_variance_ratio_)\n",
    "print('pca.singular_values_', pca1.singular_values_)\n",
    "pca2 = PCA(n_components=1024)\n",
    "x2 = pca2.fit_transform(x2)\n",
    "print('pca.explained_variance_ratio_', pca2.explained_variance_ratio_)\n",
    "print('pca.singular_values_', pca2.singular_values_)\n",
    "print(x1.shape, x2.shape)\n",
    "\n",
    "similarities_full = []\n",
    "for i in tqdm(range(df1_filtered.shape[0])):\n",
    "    try:\n",
    "        gt_features = x1[i]\n",
    "        #print(gt_features.shape)\n",
    "        chatgpt_features = x2[i]\n",
    "        #print(chatgpt_features.shape)\n",
    "        similarity_score = cosine_similarity([gt_features], [chatgpt_features])\n",
    "        #print('row ', i, ': score=', similarity_score)\n",
    "        similarities_full.append(similarity_score)\n",
    "    except Exception as e:\n",
    "        similarity_score = 0\n",
    "        similarities_full.append(similarity_score)\n",
    "        print('Cosine error at row ', i, str(e))\n",
    "        break\n",
    "similarities_full = np.reshape(similarities_full, (-1,1))\n",
    "similarities_full = pd.DataFrame(similarities_full, columns=['Cosine similarity'])\n",
    "similarities_full.to_csv('./data/wiki_features_similarity_with_tfidf_pca.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
